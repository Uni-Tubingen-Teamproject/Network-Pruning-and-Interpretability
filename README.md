# Network Pruning and Interpretability

## Project Description

Recent work has shown that large, trained networks can be condensed  into significantly smaller scales without sacrificing performance, which is achieved through systematic pruning, the process of removing unnecessary network units. Therefore, our project aims to maintain high classification performance, while pruning the network gradually and retraining the intermediate stages of the network. We now want to investigate models that maintain meaningful performance even at high pruning levels. 









 
