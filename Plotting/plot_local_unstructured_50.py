import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

# Daten für Global Unstructured Pruning (rot)
global_pruning_rates = [0.19134368949424185,
                        0.3822005349688308, 0.5728195543418653, 0.7636763998164542]
global_accuracies_after_pruning = [0.6955, 0.7105, 0.59608, 0.01362]
global_accuracies_after_retraining = [
    [0.6955, 0.51214, 0.54736, 0.56066, 0.57578, 0.5907, 0.5909, 0.60278, 0.61098, 0.6167, 0.6258, 0.6375, 0.6392, 0.65188, 0.65676, 0.65974, 0.6681, 0.67082, 0.67894, 0.68268, 0.68212, 0.68174, 0.69052, 0.69234, 0.69728, 0.69962,
     0.70472, 0.70788, 0.70164, 0.70762, 0.70962, 0.71044, 0.7116, 0.7141, 0.71176, 0.71554, 0.7155, 0.71898, 0.71842, 0.71916, 0.72074, 0.72102, 0.72216, 0.72192, 0.7226, 0.72178, 0.72402, 0.72328, 0.72332, 0.72374, 0.72488],
    [0.7105, 0.49038, 0.51518, 0.52882, 0.56872, 0.57064, 0.58236, 0.59738, 0.60474, 0.61992, 0.62848, 0.63548, 0.63998, 0.65012, 0.65172, 0.6585, 0.66904, 0.67682, 0.67966, 0.68352, 0.68586, 0.68506, 0.69224, 0.6934, 0.69644, 0.70226,
     0.70422, 0.70486, 0.7063, 0.706, 0.71148, 0.71164, 0.71404, 0.71476, 0.71482, 0.71588, 0.71706, 0.72056, 0.71862, 0.7199, 0.72044, 0.72042, 0.72062, 0.72084, 0.72286, 0.72478, 0.71878, 0.72324, 0.72338, 0.72458, 0.72226],
    [0.59608, 0.47084, 0.50694, 0.53818, 0.5585, 0.57326, 0.5854, 0.59908, 0.59014, 0.61846, 0.61588, 0.63284, 0.63804, 0.64806, 0.64774, 0.65858, 0.66004, 0.66812, 0.66904, 0.68074, 0.68394, 0.68066, 0.68972, 0.687, 0.69156, 0.6928,
     0.69602, 0.69878, 0.70064, 0.70358, 0.70786, 0.70486, 0.70676, 0.70708, 0.71126, 0.70946, 0.71054, 0.71156, 0.71122, 0.71366, 0.71394, 0.71294, 0.7126, 0.71112, 0.715, 0.71524, 0.7129, 0.7143, 0.71592, 0.71544, 0.71658],
    [0.01362, 0.41168, 0.46332, 0.49496, 0.51884, 0.5288, 0.53538, 0.55532, 0.5683, 0.57096, 0.57562, 0.59082, 0.60196, 0.60106, 0.61358, 0.62228, 0.61852, 0.62538, 0.62648, 0.62872, 0.63234, 0.64566, 0.64342, 0.64708, 0.64564, 0.6508,
     0.65536, 0.6568, 0.65646, 0.66268, 0.66364, 0.66336, 0.66376, 0.6655, 0.66676, 0.66956, 0.66806, 0.66896, 0.67092, 0.66938, 0.6709, 0.6733, 0.6716, 0.67206, 0.67262, 0.67384, 0.67318, 0.6735, 0.67212, 0.67452, 0.6757]
]

# Daten für Local Unstructured Pruning (blau)
local_pruning_rates = [0.18868790640283828,
                       0.383346122315363, 0.5717649005047509, 0.7699822889503195]
local_accuracies_after_retraining = [
    [0.69566, 0.51426, 0.54234, 0.56032, 0.55794, 0.57368, 0.59672, 0.60124, 0.61268, 0.61282, 0.6287, 0.63228, 0.6401, 0.6511, 0.6561, 0.65452, 0.6634, 0.66658, 0.67338, 0.68144, 0.6802, 0.68782, 0.69266, 0.69228, 0.69838, 0.69848,
     0.70562, 0.70378, 0.70374, 0.70854, 0.7105, 0.70864, 0.71108, 0.71366, 0.7142, 0.71634, 0.71586, 0.71642, 0.71802, 0.71938, 0.72, 0.7192, 0.7213, 0.72038, 0.72088, 0.72228, 0.72268, 0.72266, 0.72336, 0.72238, 0.72324],
    [0.66294, 0.54512, 0.53602, 0.56416, 0.57532, 0.58876, 0.5927, 0.60644, 0.6115, 0.6276, 0.62276, 0.63404, 0.64482, 0.64898, 0.65054, 0.65952, 0.66994, 0.66804, 0.67246, 0.6785, 0.68556, 0.68652, 0.68726, 0.69392, 0.69832, 0.69878,
     0.7004, 0.69972, 0.70286, 0.70766, 0.708, 0.70848, 0.71238, 0.7119, 0.7118, 0.7152, 0.7126, 0.71452, 0.71522, 0.717, 0.71666, 0.71896, 0.71756, 0.71784, 0.7198, 0.71856, 0.71916, 0.72042, 0.72012, 0.7209, 0.71992],
    [0.36514, 0.53804, 0.54772, 0.56066, 0.56254, 0.5918, 0.58074, 0.61356, 0.60696, 0.6182, 0.62204, 0.63326, 0.63718, 0.64498, 0.65076, 0.65844, 0.65886, 0.66098, 0.6668, 0.66798, 0.67656, 0.67734, 0.68494, 0.68636, 0.68476, 0.69212,
     0.69414, 0.6905, 0.69752, 0.69938, 0.69834, 0.70124, 0.70172, 0.70212, 0.70358, 0.70544, 0.7052, 0.70926, 0.70676, 0.70792, 0.70982, 0.70916, 0.7092, 0.71048, 0.71058, 0.70994, 0.71206, 0.71192, 0.71172, 0.71194, 0.71198],
    [0.00146, 0.47056, 0.50134, 0.50568, 0.52858, 0.54212, 0.54664, 0.55612, 0.5857, 0.58526, 0.6014, 0.6022, 0.60506, 0.6126, 0.61442, 0.62066, 0.62606, 0.6355, 0.63558, 0.6418, 0.64232, 0.64848, 0.65116, 0.65554, 0.65976, 0.6583,
     0.6629, 0.664, 0.66514, 0.66936, 0.6704, 0.66938, 0.67208, 0.67304, 0.67458, 0.67708, 0.67886, 0.67772, 0.67966, 0.68042, 0.6817, 0.68014, 0.68276, 0.68018, 0.68254, 0.68264, 0.68378, 0.68322, 0.68482, 0.6839, 0.6849]
]

epochs = np.arange(0, 51)

# Erstellen des 3D-Plots
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot für Global Unstructured Pruning
for i, pruning_rate in enumerate(global_pruning_rates):
    ax.plot([pruning_rate]*51, epochs, global_accuracies_after_retraining[i],
            marker='o', color='red')

# Plot für Local Unstructured Pruning
for i, pruning_rate in enumerate(local_pruning_rates):
    ax.plot([pruning_rate]*51, epochs, local_accuracies_after_retraining[i],
            marker='o', color='blue')

# Nur einmal eine Legendenbeschreibung hinzufügen
ax.plot([], [], marker='o', color='red', label='Global Unstructured Pruning')
ax.plot([], [], marker='o', color='blue', label='Local Unstructured Pruning')

ax.set_title('Accuracy During Retraining vs Actual Pruning Rate and Epochs')
ax.set_xlabel('Actual Pruning Rate')
ax.set_ylabel('Epochs')
ax.set_zlabel('Accuracy')
ax.legend()
plt.show()
