import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt


# Daten f端r L1 Pruning
pruning_rates_l1 = [0.1889, 0.3795, 0.5711, 0.7617]
accuracies_after_pruning_l1 = [0.0662, 0.0025, 0.0016, 0.0010]
accuracies_after_retraining_l1 = [
    [0.0662, 0.49522, 0.5348, 0.54622, 0.5689, 0.56534, 0.58244, 0.57634, 0.60664, 0.61162, 0.6194, 0.62836, 0.64108, 0.64892, 0.64838, 0.65592, 0.65992, 0.66828, 0.6707, 0.6741, 0.68108, 0.68768, 0.68844, 0.6894, 0.69536, 0.7007,
        0.6989, 0.70296, 0.70404, 0.71002, 0.70824, 0.71124, 0.71144, 0.71336, 0.7154, 0.71796, 0.7162, 0.71742, 0.71598, 0.7187, 0.71928, 0.72034, 0.72132, 0.72112, 0.7215, 0.72352, 0.7234, 0.72256, 0.72332, 0.72296, 0.7240],
    [0.0025, 0.47634, 0.51794, 0.54818, 0.55686, 0.56336, 0.57928, 0.60092, 0.60092, 0.60896, 0.61882, 0.63002, 0.63714, 0.6445, 0.65222, 0.65002, 0.66052, 0.66748, 0.67018, 0.67896, 0.68328, 0.68508, 0.68942, 0.68706, 0.6964, 0.69658,
        0.70008, 0.69982, 0.70504, 0.70668, 0.7048, 0.7079, 0.71294, 0.71318, 0.71386, 0.71646, 0.71618, 0.71704, 0.71692, 0.71882, 0.71954, 0.72028, 0.72052, 0.72056, 0.7197, 0.72014, 0.72212, 0.72142, 0.72206, 0.72182, 0.7218],
    [0.0016, 0.44062, 0.48312, 0.52952, 0.54972, 0.55094, 0.56748, 0.58664, 0.5985, 0.60418, 0.61092, 0.6164, 0.63218, 0.63998, 0.6462, 0.65566, 0.65902, 0.66224, 0.67312, 0.67202, 0.67752, 0.68148, 0.68396, 0.69094, 0.69438, 0.69424,
        0.6973, 0.70036, 0.70356, 0.70344, 0.70694, 0.70896, 0.71148, 0.71114, 0.7134, 0.714, 0.71622, 0.7158, 0.71622, 0.71808, 0.71764, 0.71888, 0.71916, 0.71886, 0.72046, 0.72054, 0.71984, 0.7196, 0.72224, 0.722, 0.7229],
    [0.0010, 0.3163, 0.4095, 0.43704, 0.47498, 0.50662, 0.51774, 0.54448, 0.55464, 0.5688, 0.57514, 0.58734, 0.60492, 0.6137, 0.6146, 0.6228, 0.63792, 0.63646, 0.64522, 0.65016, 0.65626, 0.6611, 0.66506, 0.66584, 0.66982, 0.67496,
        0.67914, 0.6791, 0.6816, 0.68806, 0.68796, 0.69126, 0.69072, 0.6878, 0.69548, 0.69774, 0.69692, 0.69782, 0.69914, 0.69996, 0.70066, 0.70296, 0.70382, 0.70198, 0.70274, 0.7035, 0.70382, 0.70366, 0.7052, 0.70562, 0.70506]
]

# Daten f端r Random Pruning
pruning_rates_random = [0.1889, 0.3795, 0.5711, 0.7617]
accuracies_after_pruning_random = [0.0015, 0.0010, 0.0010, 0.0010]
accuracies_after_retraining_random = [
    [0.0015, 0.48396, 0.51866, 0.53516, 0.55588, 0.57092, 0.57494, 0.59368, 0.6063, 0.60256, 0.63004,
     0.63132, 0.6414, 0.64414, 0.6443, 0.65714, 0.66276, 0.6668, 0.67458, 0.67732, 0.67838,
     0.68648, 0.68502, 0.69534, 0.69374, 0.69822, 0.69982, 0.70198, 0.70568, 0.70826, 0.70828,
     0.7117, 0.7139, 0.71144, 0.71662, 0.71616, 0.71758, 0.71796, 0.71856, 0.71992, 0.72088,
     0.7203, 0.72274, 0.72218, 0.72188, 0.72356, 0.72226, 0.7242, 0.72456, 0.72368, 0.7238],
    [0.0010, 0.4614, 0.49948, 0.5228, 0.5336, 0.56208, 0.5749, 0.5951, 0.5988, 0.60578, 0.61894,
     0.62588, 0.63018, 0.64518, 0.64254, 0.65256, 0.66294, 0.66392, 0.66916, 0.67344, 0.67732,
     0.68486, 0.68668, 0.68586, 0.69352, 0.69466, 0.69828, 0.70102, 0.70482, 0.70784, 0.70746,
     0.70966, 0.70856, 0.713, 0.71158, 0.71296, 0.71622, 0.71546, 0.71738, 0.71734, 0.718,
     0.7182, 0.7183, 0.71954, 0.7207, 0.72126, 0.72126, 0.7211, 0.72126, 0.72196, 0.72276],
    [0.0010, 0.2657, 0.36834, 0.4097, 0.44888, 0.47448, 0.48868, 0.51734, 0.52502, 0.53652, 0.56178,
     0.56178, 0.57926, 0.58736, 0.59892, 0.61, 0.60986, 0.62294, 0.62534, 0.62762, 0.6412,
     0.63982, 0.6458, 0.64702, 0.65388, 0.65912, 0.6609, 0.665, 0.66902, 0.67104, 0.67286,
     0.6764, 0.67566, 0.67864, 0.6792, 0.6823, 0.68296, 0.68452, 0.68634, 0.6865, 0.68604,
     0.68742, 0.68818, 0.68752, 0.6916, 0.69056, 0.69152, 0.68894, 0.69208, 0.69238, 0.6921],
    [0.0010, 0.24382, 0.33796, 0.40312, 0.44084, 0.47508, 0.49766, 0.51518, 0.5318, 0.54252, 0.55136,
     0.5628, 0.57034, 0.5819, 0.5791, 0.58944, 0.59884, 0.60034, 0.60424, 0.6081, 0.6108,
     0.61376, 0.61726, 0.61784, 0.61954, 0.62464, 0.62272, 0.6241, 0.62692, 0.62966, 0.63022,
     0.63016, 0.63032, 0.63246, 0.63244, 0.6333, 0.63224, 0.6324, 0.633, 0.6342, 0.6348,
     0.6337, 0.63466, 0.63456, 0.63572, 0.63568, 0.636, 0.6365, 0.63634, 0.63732, 0.6359]
]

epochs = np.arange(0, 51)

# Erstellen des 3D-Plots
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot f端r L1 Pruning
for i, pruning_rate in enumerate(pruning_rates_l1):
    ax.plot([pruning_rate]*51, epochs, accuracies_after_retraining_l1[i],
            marker='o', color='red', label=f'Connection Sparsity L1' if i == 0 else "")

# Plot f端r Random Pruning
for i, pruning_rate in enumerate(pruning_rates_random):
    ax.plot([pruning_rate]*51, epochs, accuracies_after_retraining_random[i],
            marker='o', color='blue', label=f'Connection Sparsity Random' if i == 0 else "")

ax.set_title('Accuracy During Retraining vs Actual Pruning Rate and Epochs')
ax.set_xlabel('Actual Pruning Rate')
ax.set_ylabel('Epochs')
ax.set_zlabel('Accuracy')
ax.legend()
plt.show()

